{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393a3afd",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6816f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aidan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\aidan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from datetime import timedelta\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "sw = stopwords.words('english')\n",
    "import janitor\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "tb = TextBlob('')\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kruskal\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import interact_manual, interactive_output\n",
    "from IPython.display import display, clear_output\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "import spacy\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "tb = TextBlob('')\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from random import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import winsound\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('words')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import words\n",
    "from nltk.util import ngrams\n",
    "import random\n",
    "from wordcloud import WordCloud\n",
    "import xgboost as xgb\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b905455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words(texts, n_top=10):\n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    word_matrix = vectorizer.fit_transform(texts)\n",
    "    sum_words = word_matrix.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n_top]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84250961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_agency_involvement(data, agency_list):\n",
    "    results = {}\n",
    "    \n",
    "    for agency in agency_list:\n",
    "        agency_data = {\n",
    "            'involvement_percentage': (data[agency].mean()) * 100,\n",
    "            'text_analysis': {},\n",
    "            'model_performance': {},\n",
    "            'feature_importance': {}\n",
    "        }\n",
    "        \n",
    "        # Splitting text based on agency involvement\n",
    "        agency_present_text = data[data[agency] == 1]['combined_text'].dropna()\n",
    "        agency_absent_text = data[data[agency] == 0]['combined_text'].dropna()\n",
    "        \n",
    "        # Common words analysis\n",
    "        common_words_present = get_most_common_words(agency_present_text)\n",
    "        common_words_absent = get_most_common_words(agency_absent_text)\n",
    "        \n",
    "        # Relative frequency analysis\n",
    "        total_words_present = sum(freq for _, freq in common_words_present)\n",
    "        total_words_absent = sum(freq for _, freq in common_words_absent)\n",
    "        relative_freq_present = {word: freq / total_words_present for word, freq in common_words_present}\n",
    "        relative_freq_absent = {word: freq / total_words_absent for word, freq in common_words_absent}\n",
    "        \n",
    "        # Comparative frequency\n",
    "        comparative_freq = {word: relative_freq_present.get(word, 0) - relative_freq_absent.get(word, 0) for word in set(relative_freq_present) | set(relative_freq_absent)}\n",
    "        sorted_comparative_freq = sorted(comparative_freq.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        agency_data['text_analysis'] = {\n",
    "            'common_words_present': common_words_present,\n",
    "            'common_words_absent': common_words_absent,\n",
    "            'relative_freq_present' : relative_freq_present,\n",
    "            'relative_freq_absent' : relative_freq_absent,\n",
    "            'sorted_comparative_freq': sorted_comparative_freq\n",
    "        }\n",
    "        \n",
    "        # Model training and evaluation\n",
    "        X = tfidf_vectorizer.fit_transform(data['combined_text'].fillna(''))\n",
    "        y = data[agency]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        lr_model = LogisticRegression(max_iter=1000)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = lr_model.predict(X_test)\n",
    "        \n",
    "        # Storing model performance\n",
    "        agency_data['model_performance'] = {\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'f1': f1_score(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        coefficients = lr_model.coef_[0]\n",
    "        features_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "        features_sorted = features_df.sort_values(by='Coefficient', ascending=False)\n",
    "        \n",
    "        agency_data['feature_importance'] = {\n",
    "            'positive': features_sorted.head(10).to_dict('records'),\n",
    "            'negative': features_sorted.tail(10).to_dict('records')\n",
    "        }\n",
    "        \n",
    "        # Store results for current agency\n",
    "        results[agency] = agency_data\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6220c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_agency_stats\u001b[39m(df \u001b[38;5;241m=\u001b[39m \u001b[43mflat\u001b[49m, agency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnps\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      2\u001b[0m     f_rows \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magency\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m agency]\n\u001b[0;32m      4\u001b[0m     agency_rf_pres \u001b[38;5;241m=\u001b[39m f_rows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_freq_present\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'flat' is not defined"
     ]
    }
   ],
   "source": [
    "def get_agency_stats(df = flat, agency = 'nps'):\n",
    "    f_rows = df[df['agency'] == agency]\n",
    "    \n",
    "    agency_rf_pres = f_rows['relative_freq_present'].iloc[0]\n",
    "    agency_rf_abs = f_rows['relative_freq_absent'].iloc[0]\n",
    "    agency_involvement_percentage = f_rows['involvement_percentage']\n",
    "    agency_common_words_present = f_rows['common_words_present']\n",
    "    agency_common_words_absent = f_rows['common_words_absent']\n",
    "    agency_relative_freq_present = f_rows['relative_freq_present']\n",
    "    agency_relative_freq_absent = f_rows['relative_freq_absent']\n",
    "    agency_sorted_comparative_freq = f_rows['sorted_comparative_freq']\n",
    "    agency_accuracy = f_rows['accuracy']\n",
    "    agency_precision = f_rows['precision']\n",
    "    agency_recall = f_rows['recall']\n",
    "    agency_f1 = f_rows['f1']\n",
    "    agency_positive = f_rows['positive']\n",
    "    agency_negative = f_rows['negative']\n",
    "\n",
    "    # Return all extracted values\n",
    "    return {\n",
    "        'involvement_percentage': agency_involvement_percentage,\n",
    "        'common_words_present': agency_common_words_present,\n",
    "        'common_words_absent': agency_common_words_absent,\n",
    "        'relative_freq_present': agency_relative_freq_present,\n",
    "        'relative_freq_absent': agency_relative_freq_absent,\n",
    "        'sorted_comparative_freq': agency_sorted_comparative_freq,\n",
    "        'accuracy': agency_accuracy,\n",
    "        'precision': agency_precision,\n",
    "        'recall': agency_recall,\n",
    "        'f1': agency_f1,\n",
    "        'positive': agency_positive,\n",
    "        'negative': agency_negative\n",
    "    }\n",
    "    return agency_rf_pres, agency_rf_abs\n",
    "\n",
    "def pretty_print_results(results):\n",
    "    # Initialize PrettyPrinter\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    \n",
    "    print(\"Agency Stats Overview:\\n\")\n",
    "    \n",
    "    # Table header\n",
    "    print(f\"{'Metric':<25} | {'Value'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Loop through each result, print formatted string for numbers and use pprint for complex types\n",
    "    for key, value in results.items():\n",
    "        if isinstance(value.iloc[0], (float, int)):\n",
    "            # Format numbers to two decimal places if it's a float/int\n",
    "            print(f\"{key:<25} | {value.iloc[0]:.2f}\")\n",
    "        else:\n",
    "            # Use pretty print for dictionaries, lists, etc.\n",
    "            print(f\"{key:<25} :\")\n",
    "            pp.pprint(value.iloc[0])\n",
    "            print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37460a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1f4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
